{
  "cells": [
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "92WHLz8346Yf"
      },
      "source": [
        "# **üè† Î∂ÄÎèôÏÇ∞ Ïã§Í±∞ÎûòÍ∞Ä Team 3 DTQ First Trial code**\n",
        "\n",
        "## Contents\n",
        "\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "2-DJzJjvO88V"
      },
      "source": [
        "## Step 1: Library Imports\n",
        "- ÌïÑÏöîÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨Î•º Î∂àÎü¨ÏòµÎãàÎã§."
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 1,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PKs1Mj7OcWU0",
        "outputId": "d142df48-acc5-4bca-c9be-18575aa6a6dc"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[33mWARNING: The directory '/data/ephemeral/home/.cache/pip' or its parent directory is not owned or is not writable by the current user. The cache has been disabled. Check the permissions and owner of that directory. If executing pip with sudo, you should use sudo's -H flag.\u001b[0m\u001b[33m\n",
            "\u001b[0mRequirement already satisfied: eli5==0.13.0 in /opt/conda/lib/python3.10/site-packages (0.13.0)\n",
            "Requirement already satisfied: attrs>17.1.0 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (23.1.0)\n",
            "Requirement already satisfied: jinja2>=3.0.0 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (3.1.2)\n",
            "Requirement already satisfied: numpy>=1.9.0 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.23.5)\n",
            "Requirement already satisfied: scipy in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.11.3)\n",
            "Requirement already satisfied: six in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.16.0)\n",
            "Requirement already satisfied: scikit-learn>=0.20 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (1.2.2)\n",
            "Requirement already satisfied: graphviz in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (0.20.1)\n",
            "Requirement already satisfied: tabulate>=0.7.7 in /opt/conda/lib/python3.10/site-packages (from eli5==0.13.0) (0.9.0)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /opt/conda/lib/python3.10/site-packages (from jinja2>=3.0.0->eli5==0.13.0) (2.1.1)\n",
            "Requirement already satisfied: joblib>=1.1.1 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20->eli5==0.13.0) (1.3.2)\n",
            "Requirement already satisfied: threadpoolctl>=2.0.0 in /opt/conda/lib/python3.10/site-packages (from scikit-learn>=0.20->eli5==0.13.0) (3.2.0)\n",
            "\u001b[33mWARNING: Running pip as the 'root' user can result in broken permissions and conflicting behaviour with the system package manager. It is recommended to use a virtual environment instead: https://pip.pypa.io/warnings/venv\u001b[0m\u001b[33m\n",
            "Reading package lists... Done\n",
            "Building dependency tree       \n",
            "Reading state information... Done\n",
            "fonts-nanum is already the newest version (20180306-3).\n",
            "0 upgraded, 0 newly installed, 0 to remove and 14 not upgraded.\n"
          ]
        }
      ],
      "source": [
        "!pip install eli5==0.13.0\n",
        "\n",
        "# ÌïúÍ∏Ä Ìè∞Ìä∏ ÏÇ¨Ïö©ÏùÑ ÏúÑÌïú ÎùºÏù¥Î∏åÎü¨Î¶¨ÏûÖÎãàÎã§.\n",
        "!apt-get install -y fonts-nanum"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 13,
      "metadata": {},
      "outputs": [],
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from sklearn.preprocessing import OneHotEncoder, KBinsDiscretizer\n",
        "from sklearn.impute import SimpleImputer\n",
        "from sklearn.feature_extraction.text import TfidfVectorizer\n",
        "from sklearn.pipeline import Pipeline\n",
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.optim as optim\n",
        "from torch.utils.data import Dataset, DataLoader, TensorDataset\n",
        "\n",
        "# Ensure the torch is using GPU if available\n",
        "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 14,
      "metadata": {
        "id": "d-NiCLGs4ZpM"
      },
      "outputs": [],
      "source": [
        "# visualization\n",
        "import matplotlib.pyplot as plt\n",
        "import matplotlib.font_manager as fm\n",
        "fe = fm.FontEntry(\n",
        "    fname=r'/usr/share/fonts/truetype/nanum/NanumGothic.ttf', # ttf ÌååÏùºÏù¥ Ï†ÄÏû•ÎêòÏñ¥ ÏûàÎäî Í≤ΩÎ°ú\n",
        "    name='NanumBarunGothic')                        # Ïù¥ Ìè∞Ìä∏Ïùò ÏõêÌïòÎäî Ïù¥Î¶Ñ ÏÑ§Ï†ï\n",
        "fm.fontManager.ttflist.insert(0, fe)              # MatplotlibÏóê Ìè∞Ìä∏ Ï∂îÍ∞Ä\n",
        "plt.rcParams.update({'font.size': 10, 'font.family': 'NanumBarunGothic'}) # Ìè∞Ìä∏ ÏÑ§Ï†ï\n",
        "plt.rc('font', family='NanumBarunGothic')\n",
        "import seaborn as sns\n",
        "\n",
        "# utils\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "from tqdm import tqdm\n",
        "import pickle\n",
        "import warnings;warnings.filterwarnings('ignore')\n",
        "\n",
        "# Model\n",
        "from sklearn.preprocessing import LabelEncoder\n",
        "from sklearn.model_selection import train_test_split\n",
        "from sklearn.metrics import mean_squared_error\n",
        "from sklearn.ensemble import RandomForestRegressor\n",
        "from sklearn import metrics\n",
        "\n",
        "import eli5\n",
        "from eli5.sklearn import PermutationImportance"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "OPJvYT0OPAWS"
      },
      "source": [
        "## Step 2: Data Preprocessing Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 15,
      "metadata": {},
      "outputs": [],
      "source": [
        "def one_hot_encode(df, columns):\n",
        "    encoder = OneHotEncoder(sparse=False)\n",
        "    encoded_df = pd.DataFrame(encoder.fit_transform(df[columns]), columns=encoder.get_feature_names_out(columns))\n",
        "    return pd.concat([df.drop(columns, axis=1), encoded_df], axis=1)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 16,
      "metadata": {},
      "outputs": [],
      "source": [
        "def impute_missing_values(df, strategy='median'):\n",
        "    imputer = SimpleImputer(strategy=strategy)\n",
        "    imputed_df = pd.DataFrame(imputer.fit_transform(df), columns=df.columns)\n",
        "    return imputed_df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 17,
      "metadata": {},
      "outputs": [],
      "source": [
        "def smooth_ridit_transform(df, columns):\n",
        "    for col in columns:\n",
        "        sorted_col = df[col].sort_values()\n",
        "        rank = sorted_col.rank(pct=True)\n",
        "        ridit_score = 2 * rank - 1\n",
        "        df[col] = ridit_score\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 18,
      "metadata": {},
      "outputs": [],
      "source": [
        "def bin_numerical_variables(df, columns, n_bins=5):\n",
        "    discretizer = KBinsDiscretizer(n_bins=n_bins, encode='ordinal', strategy='quantile')\n",
        "    for col in columns:\n",
        "        df[col + '_bin'] = discretizer.fit_transform(df[[col]]).astype(int)\n",
        "    return df\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 19,
      "metadata": {},
      "outputs": [],
      "source": [
        "def tfidf_transform(df, text_column):\n",
        "    vectorizer = TfidfVectorizer(ngram_range=(1, 3), stop_words='english')\n",
        "    tfidf_matrix = vectorizer.fit_transform(df[text_column])\n",
        "    tfidf_df = pd.DataFrame(tfidf_matrix.toarray(), columns=vectorizer.get_feature_names_out())\n",
        "    return tfidf_df\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KVjw5Cnz24nz"
      },
      "source": [
        "## Step 3: Custom Dataset Class for PyTorch"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "id": "vltXVoeRhZiI"
      },
      "outputs": [],
      "source": [
        "class RealEstateDataset(Dataset):\n",
        "    def __init__(self, features, targets):\n",
        "        self.features = torch.tensor(features, dtype=torch.float32)\n",
        "        self.targets = torch.tensor(targets, dtype=torch.float32)\n",
        "    \n",
        "    def __len__(self):\n",
        "        return len(self.features)\n",
        "    \n",
        "    def __getitem__(self, idx):\n",
        "        return self.features[idx], self.targets[idx]\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "uXfXRevr3dfe"
      },
      "source": [
        "## Step 4: Define the PyTorch Model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 21,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "9E__0jEyyXIA",
        "outputId": "ffb3cc6e-d337-4ed6-96d1-ddf96dc97449"
      },
      "outputs": [],
      "source": [
        "class SimpleResidualNetwork(nn.Module):\n",
        "    def __init__(self, input_dim):\n",
        "        super(SimpleResidualNetwork, self).__init__()\n",
        "        self.fc1 = nn.Linear(input_dim, 64)\n",
        "        self.relu = nn.ReLU()\n",
        "        self.fc2 = nn.Linear(64, 1)\n",
        "        self.residual = nn.Linear(input_dim, 1)\n",
        "    \n",
        "    def forward(self, x):\n",
        "        out = self.relu(self.fc1(x))\n",
        "        out = self.fc2(out) + self.residual(x)\n",
        "        return out\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "F0Ga4ljBNYIy"
      },
      "source": [
        "## Step 5: Training and Inference Functions"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 158
        },
        "id": "7LC7NuRaD_Dd",
        "outputId": "c2827163-dbdd-4c8c-d35b-1c325b8d14c0"
      },
      "outputs": [],
      "source": [
        "def train_model(model, dataloader, criterion, optimizer, num_epochs=25):\n",
        "    model.train()\n",
        "    rmse_history = []\n",
        "    \n",
        "    for epoch in range(num_epochs):\n",
        "        epoch_losses = []\n",
        "        for inputs, targets in dataloader:\n",
        "            inputs, targets = inputs.to(device), targets.to(device)\n",
        "            \n",
        "            optimizer.zero_grad()\n",
        "            outputs = model(inputs)\n",
        "            loss = criterion(outputs, targets)\n",
        "            loss.backward()\n",
        "            optimizer.step()\n",
        "            \n",
        "            epoch_losses.append(torch.sqrt(loss).item())\n",
        "        \n",
        "        epoch_rmse = np.mean(epoch_losses)\n",
        "        rmse_history.append(epoch_rmse)\n",
        "        print(f\"Epoch [{epoch+1}/{num_epochs}], RMSE: {epoch_rmse:.4f}\")\n",
        "    \n",
        "    return model, rmse_history\n",
        "\n",
        "def plot_rmse(rmse_history):\n",
        "    plt.figure(figsize=(10, 5))\n",
        "    plt.plot(rmse_history, label='RMSE')\n",
        "    plt.xlabel('Epoch')\n",
        "    plt.ylabel('RMSE')\n",
        "    plt.title('RMSE over Epochs')\n",
        "    plt.legend()\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "id": "0HXvn8ZSa1kt"
      },
      "outputs": [],
      "source": [
        "def predict(model, dataloader):\n",
        "    model.eval()\n",
        "    predictions = []\n",
        "    with torch.no_grad():\n",
        "        for inputs, _ in dataloader:\n",
        "            inputs = inputs.to(device)\n",
        "            outputs = model(inputs)\n",
        "            predictions.extend(outputs.cpu().numpy())\n",
        "    return np.array(predictions)\n"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "KlxtDBDNNa6Y"
      },
      "source": [
        "## Step 6: Putting It All Together"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "id": "Tn36fIuB42aM"
      },
      "outputs": [
        {
          "ename": "",
          "evalue": "",
          "output_type": "error",
          "traceback": [
            "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
            "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
            "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
            "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
          ]
        }
      ],
      "source": [
        "# Load train and test data\n",
        "train_data = pd.read_csv('/data/ephemeral/home/train.csv')\n",
        "test_data = pd.read_csv('/data/ephemeral/home/test.csv')\n",
        "\n",
        "# Select only the required columns\n",
        "selected_columns = ['ÏãúÍµ∞Íµ¨', 'Î≤àÏßÄ', 'ÏïÑÌååÌä∏Î™Ö', 'Ï†ÑÏö©Î©¥Ï†Å(„é°)', 'Í≥ÑÏïΩÎÖÑÏõî', 'Í±¥Ï∂ïÎÖÑÎèÑ', 'target']\n",
        "train_data = train_data[selected_columns]\n",
        "test_data = test_data[['ÏãúÍµ∞Íµ¨', 'Î≤àÏßÄ', 'ÏïÑÌååÌä∏Î™Ö', 'Ï†ÑÏö©Î©¥Ï†Å(„é°)', 'Í≥ÑÏïΩÎÖÑÏõî', 'Í±¥Ï∂ïÎÖÑÎèÑ']]\n",
        "\n",
        "# Data preprocessing\n",
        "train_data = one_hot_encode(train_data, columns=['ÏãúÍµ∞Íµ¨', 'Î≤àÏßÄ', 'ÏïÑÌååÌä∏Î™Ö'])\n",
        "train_data = impute_missing_values(train_data)\n",
        "train_data = smooth_ridit_transform(train_data, columns=['Ï†ÑÏö©Î©¥Ï†Å(„é°)', 'Í≥ÑÏïΩÎÖÑÏõî', 'Í±¥Ï∂ïÎÖÑÎèÑ'])\n",
        "\n",
        "test_data = one_hot_encode(test_data, columns=['ÏãúÍµ∞Íµ¨', 'Î≤àÏßÄ', 'ÏïÑÌååÌä∏Î™Ö'])\n",
        "test_data = impute_missing_values(test_data)\n",
        "test_data = smooth_ridit_transform(test_data, columns=['Ï†ÑÏö©Î©¥Ï†Å(„é°)', 'Í≥ÑÏïΩÎÖÑÏõî', 'Í±¥Ï∂ïÎÖÑÎèÑ'])\n",
        "\n",
        "# Prepare dataset for PyTorch\n",
        "train_features = train_data.drop(columns=['target']).values\n",
        "train_targets = train_data['target'].values\n",
        "train_dataset = RealEstateDataset(train_features, train_targets)\n",
        "train_dataloader = DataLoader(train_dataset, batch_size=32, shuffle=True)\n",
        "\n",
        "test_features = test_data.values\n",
        "test_dataset = RealEstateDataset(test_features)\n",
        "test_dataloader = DataLoader(test_dataset, batch_size=32, shuffle=False)\n",
        "\n",
        "# Initialize model, criterion, and optimizer\n",
        "model = SimpleResidualNetwork(input_dim=train_features.shape[1]).to(device)\n",
        "criterion = nn.MSELoss()\n",
        "optimizer = optim.Adam(model.parameters(), lr=0.001)\n",
        "\n",
        "# Train model\n",
        "trained_model, rmse_history = train_model(model, train_dataloader, criterion, optimizer, num_epochs=25)\n",
        "\n",
        "# Plot RMSE history\n",
        "plot_rmse(rmse_history)\n",
        "\n",
        "# Make predictions\n",
        "predictions = predict(trained_model, test_dataloader)\n",
        "\n",
        "# Save predictions\n",
        "np.savetxt('predictions.csv', predictions, delimiter=',')\n",
        "\n"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3.10.13 ('base')",
      "language": "python",
      "name": "python3"
    },
    "language_info": {
      "codemirror_mode": {
        "name": "ipython",
        "version": 3
      },
      "file_extension": ".py",
      "mimetype": "text/x-python",
      "name": "python",
      "nbconvert_exporter": "python",
      "pygments_lexer": "ipython3",
      "version": "3.10.13"
    },
    "vscode": {
      "interpreter": {
        "hash": "d4d1e4263499bec80672ea0156c357c1ee493ec2b1c70f0acce89fc37c4a6abe"
      }
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
